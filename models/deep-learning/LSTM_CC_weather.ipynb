{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LSTM Model with Community Clustered Data\n",
    "Reservations are aggregated by grid cells (200m x 200m) and clustered into communities. \n",
    "Reservation data including weather data.\n",
    "\n",
    "Inspired by: https://github.com/HAKO411/Deep-Learning-for-Short-term-bike-sharing-demand-prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sdxOIwGW5cDQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1662333949748,
     "user_tz": -120,
     "elapsed": 3372,
     "user": {
      "displayName": "Tri Dung Huynh",
      "userId": "00185777558728664115"
     }
    }
   },
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "Preparing data to train the cnn-lstm model"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# variables\n",
    "training_data_filepath = '../../pickles/reservations_training.pickle'\n",
    "validation_data_filepath = '../../pickles/reservations_validation.pickle'\n",
    "\n",
    "results_filepath = '../../pickles/results/lstm_cc_weather_results.pickle'"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# training variables\n",
    "num_units = 50\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "loss_function = 'mean_squared_error'\n",
    "seed = 42\n",
    "dropout = 0.1\n",
    "\n",
    "num_input_features = 5"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0O27k085lPe",
    "outputId": "ad545b1a-d54f-4c41-92fc-c7e1b27f1b6c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1662333996900,
     "user_tz": -120,
     "elapsed": 47157,
     "user": {
      "displayName": "Tri Dung Huynh",
      "userId": "00185777558728664115"
     }
    }
   },
   "source": [
    "# load data\n",
    "training_input_data = pd.read_pickle(training_data_filepath)\n",
    "training_input_data.set_index('startTime', inplace=True)\n",
    "training_input_data.index = pd.to_datetime(training_input_data.index)\n",
    "training_input_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load data\n",
    "validation_input_data = pd.read_pickle(validation_data_filepath)\n",
    "validation_input_data.set_index('startTime', inplace=True)\n",
    "validation_input_data.index = pd.to_datetime(validation_input_data.index)\n",
    "validation_input_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# transform data\n",
    "training_demand_data = training_input_data.resample('h').small_grid_id.value_counts().unstack().fillna(0)\n",
    "training_weather_data = training_input_data.resample('h').mean().drop(columns=['large_grid_id', 'small_grid_id', 'community_small_grid_id', 'community_voronoi_grid_id', 'voronoi_grid_id', 'endLat', 'endLon', 'startLat', 'startLon', 'endTime'])\n",
    "training_data = pd.merge(training_weather_data, training_demand_data, left_index=True, right_index=True, how='inner')\n",
    "training_data.set_index(pd.to_datetime(training_data.index), inplace=True)\n",
    "training_data.sort_index(inplace=True)\n",
    "training_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# transform data\n",
    "validation_demand_data = validation_input_data.resample('h').small_grid_id.value_counts().unstack().fillna(0)\n",
    "validation_weather_data = validation_input_data.resample('h').mean().drop(columns=['large_grid_id', 'small_grid_id', 'community_small_grid_id', 'community_voronoi_grid_id', 'voronoi_grid_id', 'endLat', 'endLon', 'startLat', 'startLon', 'endTime'])\n",
    "validation_data = pd.merge(validation_weather_data, validation_demand_data, left_index=True, right_index=True, how='inner')\n",
    "validation_data.set_index(pd.to_datetime(validation_data.index), inplace=True)\n",
    "validation_data.sort_index(inplace=True)\n",
    "validation_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# decompose timestamp\n",
    "training_data['hour'] = training_data.index.hour\n",
    "training_data['day'] = training_data.index.dayofweek\n",
    "training_data['month'] = training_data.index.month\n",
    "training_data.columns = training_data.columns.astype(str)\n",
    "training_data = training_data.reindex(sorted(training_data.columns, reverse=True), axis=1)\n",
    "training_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# decompose timestamp\n",
    "validation_data['hour'] = validation_data.index.hour\n",
    "validation_data['day'] = validation_data.index.dayofweek\n",
    "validation_data['month'] = validation_data.index.month\n",
    "validation_data.columns = validation_data.columns.astype(str)\n",
    "validation_data = validation_data.reindex(sorted(validation_data.columns, reverse=True), axis=1)\n",
    "validation_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "id": "13AIvcHn5z_h",
    "outputId": "98d4d12c-84bd-4f54-8065-0eef774850b7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1662333996901,
     "user_tz": -120,
     "elapsed": 17,
     "user": {
      "displayName": "Tri Dung Huynh",
      "userId": "00185777558728664115"
     }
    }
   },
   "source": [
    "# index is timestamp (hourly)\n",
    "# columns are the grid cells\n",
    "# values are the demand e.g. pickup in the timeframe\n",
    "full_demand = training_data\n",
    "full_demand.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create list of grid cells for each community\n",
    "community_lists = training_input_data.groupby('community_small_grid_id')['small_grid_id'].apply(lambda x: list(set(x)))\n",
    "\n",
    "# Convert the result to a dictionary for easier access\n",
    "community_dict = community_lists.to_dict()\n",
    "community_dict"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get values, grid-cell name and drop null values\n",
    "def get_value_name(all_cells_demand, cells):\n",
    "    station_value = all_cells_demand[['month', 'day', 'hour', 'temperature', 'precipitation'] + cells]\n",
    "    return station_value"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def prepare_data_for_model(demand_at_cell):\n",
    "    x = demand_at_cell.iloc[:, 0:num_input_features].values\n",
    "    y = demand_at_cell.iloc[:, num_input_features:].values\n",
    "\n",
    "    return x.reshape((x.shape[0], 1, x.shape[1])), y"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DG0xNr8L-TbU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1662333996904,
     "user_tz": -120,
     "elapsed": 14,
     "user": {
      "displayName": "Tri Dung Huynh",
      "userId": "00185777558728664115"
     }
    }
   },
   "source": [
    "def lstm_model(name, units, training_x, validation_x, training_y, validation_y, num_output_features):\n",
    "    model = tf.keras.models.Sequential(name=name)\n",
    "\n",
    "    model.add(tf.keras.layers.Input(shape=(1, num_input_features)))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(units, return_sequences=True))\n",
    "    model.add(tf.keras.layers.Dropout(dropout, seed=seed))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(units, return_sequences=True))\n",
    "    model.add(tf.keras.layers.Dropout(dropout, seed=seed))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(units, return_sequences=True))\n",
    "    model.add(tf.keras.layers.Dropout(dropout, seed=seed))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(units, return_sequences=True))\n",
    "    model.add(tf.keras.layers.Dropout(dropout, seed=seed))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(units, return_sequences=False))\n",
    "    model.add(tf.keras.layers.Dropout(dropout, seed=seed))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(num_output_features))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=loss_function)\n",
    "\n",
    "    model.fit(training_x, training_y, batch_size=batch_size, epochs=epochs, validation_data=(validation_x, validation_y), verbose=0)\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Input data\n",
    "all_grid_cells_temp = full_demand\n",
    "val_data_temp = validation_data.copy()\n",
    "# run the model\n",
    "community_clusters = list()\n",
    "cluster_grid_cells = list()\n",
    "models = list()\n",
    "# loop through all the grid cells\n",
    "for i in range(len(community_dict)):\n",
    "    \n",
    "    grid_cells = community_dict[i]\n",
    "    \n",
    "    # preprocessing\n",
    "    grid_values = get_value_name(all_grid_cells_temp, list(map(str, grid_cells)))\n",
    "    val_grid_values = get_value_name(val_data_temp, list(map(str, grid_cells)))\n",
    "\n",
    "    train_x, train_y = prepare_data_for_model(grid_values)\n",
    "    val_x, val_y = prepare_data_for_model(val_grid_values)\n",
    "    \n",
    "    model_name = 'LSTM_CC_weather_' + str(i)\n",
    "    print('Training model ' + model_name)\n",
    "    \n",
    "    # LSTM modelling & forecast\n",
    "    current_model = lstm_model(model_name, num_units, train_x, val_x, train_y, val_y, len(grid_cells))\n",
    "\n",
    "    #Save result\n",
    "    community_clusters.append(i)\n",
    "    models.append(current_model)\n",
    "    cluster_grid_cells.append(grid_cells)\n",
    "\n",
    "results = pd.DataFrame({'community_clusters': community_clusters, 'cluster_grid_cells': cluster_grid_cells, 'model': models})\n",
    "\n",
    "results.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# save results\n",
    "results.to_pickle(results_filepath)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": [],
   "background_execution": "on"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
